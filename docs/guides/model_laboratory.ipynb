{"cells": [{"cell_type": "markdown", "id": "920a3c1a", "metadata": {}, "source": ["# \u6a21\u578b\u6bd4\u8f83\n", "\n", "\u6784\u5efa\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u7a0b\u5e8f\u53ef\u80fd\u6d89\u53ca\u9009\u62e9\u8bb8\u591a\u4e0d\u540c\u7684\u63d0\u793a\u3001\u6a21\u578b\u751a\u81f3\u94fe\u8def\u7684\u9009\u9879\u3002\u5728\u8fd9\u6837\u505a\u65f6\uff0c\u60a8\u5e0c\u671b\u4ee5\u4e00\u79cd\u7b80\u5355\u3001\u7075\u6d3b\u548c\u76f4\u89c2\u7684\u65b9\u5f0f\u6bd4\u8f83\u8fd9\u4e9b\u4e0d\u540c\u7684\u9009\u9879\u5728\u4e0d\u540c\u7684\u8f93\u5165\u4e0a\u7684\u6548\u679c\u3002\n", "\n", "LangChain \u63d0\u4f9b\u4e86\u4e00\u4e2a ModelLaboratory \u7684\u6982\u5ff5\uff0c\u7528\u4e8e\u6d4b\u8bd5\u548c\u5c1d\u8bd5\u4e0d\u540c\u7684\u6a21\u578b\u3002"]}, {"cell_type": "code", "execution_count": 1, "id": "ab9e95ad", "metadata": {}, "outputs": [], "source": ["from langchain import LLMChain, OpenAI, Cohere, HuggingFaceHub, PromptTemplate\n", "from langchain.model_laboratory import ModelLaboratory"]}, {"cell_type": "code", "execution_count": 2, "id": "32cb94e6", "metadata": {}, "outputs": [], "source": ["llms = [\n", "    OpenAI(temperature=0),\n", "    Cohere(model=\"command-xlarge-20221108\", max_tokens=20, temperature=0),\n", "    HuggingFaceHub(repo_id=\"google/flan-t5-xl\", model_kwargs={\"temperature\": 1}),\n", "]"]}, {"cell_type": "code", "execution_count": 3, "id": "14cde09d", "metadata": {}, "outputs": [], "source": ["model_lab = ModelLaboratory.from_llms(llms)"]}, {"cell_type": "code", "execution_count": 4, "id": "f186c741", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\u001b[1mInput:\u001b[0m\n", "What color is a flamingo?\n", "\n", "\u001b[1mOpenAI\u001b[0m\n", "Params: {'model': 'text-davinci-002', 'temperature': 0.0, 'max_tokens': 256, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'best_of': 1}\n", "\u001b[36;1m\u001b[1;3m\n", "\n", "Flamingos are pink.\u001b[0m\n", "\n", "\u001b[1mCohere\u001b[0m\n", "Params: {'model': 'command-xlarge-20221108', 'max_tokens': 20, 'temperature': 0.0, 'k': 0, 'p': 1, 'frequency_penalty': 0, 'presence_penalty': 0}\n", "\u001b[33;1m\u001b[1;3m\n", "\n", "Pink\u001b[0m\n", "\n", "\u001b[1mHuggingFaceHub\u001b[0m\n", "Params: {'repo_id': 'google/flan-t5-xl', 'temperature': 1}\n", "\u001b[38;5;200m\u001b[1;3mpink\u001b[0m\n", "\n"]}], "source": ["model_lab.compare(\"What color is a flamingo?\")"]}, {"cell_type": "code", "execution_count": 5, "id": "248b652a", "metadata": {}, "outputs": [], "source": ["prompt = PromptTemplate(\n", "    template=\"What is the capital of {state}?\", input_variables=[\"state\"]\n", ")\n", "model_lab_with_prompt = ModelLaboratory.from_llms(llms, prompt=prompt)"]}, {"cell_type": "code", "execution_count": 6, "id": "f64377ac", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\u001b[1mInput:\u001b[0m\n", "New York\n", "\n", "\u001b[1mOpenAI\u001b[0m\n", "Params: {'model': 'text-davinci-002', 'temperature': 0.0, 'max_tokens': 256, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'best_of': 1}\n", "\u001b[36;1m\u001b[1;3m\n", "\n", "The capital of New York is Albany.\u001b[0m\n", "\n", "\u001b[1mCohere\u001b[0m\n", "Params: {'model': 'command-xlarge-20221108', 'max_tokens': 20, 'temperature': 0.0, 'k': 0, 'p': 1, 'frequency_penalty': 0, 'presence_penalty': 0}\n", "\u001b[33;1m\u001b[1;3m\n", "\n", "The capital of New York is Albany.\u001b[0m\n", "\n", "\u001b[1mHuggingFaceHub\u001b[0m\n", "Params: {'repo_id': 'google/flan-t5-xl', 'temperature': 1}\n", "\u001b[38;5;200m\u001b[1;3mst john s\u001b[0m\n", "\n"]}], "source": ["model_lab_with_prompt.compare(\"New York\")"]}, {"cell_type": "code", "execution_count": 7, "id": "54336dbf", "metadata": {}, "outputs": [], "source": ["from langchain import SelfAskWithSearchChain, SerpAPIWrapper\n", "\n", "open_ai_llm = OpenAI(temperature=0)\n", "search = SerpAPIWrapper()\n", "self_ask_with_search_openai = SelfAskWithSearchChain(\n", "    llm=open_ai_llm, search_chain=search, verbose=True\n", ")\n", "\n", "cohere_llm = Cohere(temperature=0, model=\"command-xlarge-20221108\")\n", "search = SerpAPIWrapper()\n", "self_ask_with_search_cohere = SelfAskWithSearchChain(\n", "    llm=cohere_llm, search_chain=search, verbose=True\n", ")"]}, {"cell_type": "code", "execution_count": 8, "id": "6a50a9f1", "metadata": {}, "outputs": [], "source": ["chains = [self_ask_with_search_openai, self_ask_with_search_cohere]\n", "names = [str(open_ai_llm), str(cohere_llm)]"]}, {"cell_type": "code", "execution_count": 9, "id": "d3549e99", "metadata": {}, "outputs": [], "source": ["model_lab = ModelLaboratory(chains, names=names)"]}, {"cell_type": "code", "execution_count": 10, "id": "362f7f57", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\u001b[1mInput:\u001b[0m\n", "What is the hometown of the reigning men's U.S. Open champion?\n", "\n", "\u001b[1mOpenAI\u001b[0m\n", "Params: {'model': 'text-davinci-002', 'temperature': 0.0, 'max_tokens': 256, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'best_of': 1}\n", "\n", "\n", "\u001b[1m> Entering new chain...\u001b[0m\n", "What is the hometown of the reigning men's U.S. Open champion?\n", "Are follow up questions needed here:\u001b[32;1m\u001b[1;3m Yes.\n", "Follow up: Who is the reigning men's U.S. Open champion?\u001b[0m\n", "Intermediate answer: \u001b[33;1m\u001b[1;3mCarlos Alcaraz.\u001b[0m\u001b[32;1m\u001b[1;3m\n", "Follow up: Where is Carlos Alcaraz from?\u001b[0m\n", "Intermediate answer: \u001b[33;1m\u001b[1;3mEl Palmar, Spain.\u001b[0m\u001b[32;1m\u001b[1;3m\n", "So the final answer is: El Palmar, Spain\u001b[0m\n", "\u001b[1m> Finished chain.\u001b[0m\n", "\u001b[36;1m\u001b[1;3m\n", "So the final answer is: El Palmar, Spain\u001b[0m\n", "\n", "\u001b[1mCohere\u001b[0m\n", "Params: {'model': 'command-xlarge-20221108', 'max_tokens': 256, 'temperature': 0.0, 'k': 0, 'p': 1, 'frequency_penalty': 0, 'presence_penalty': 0}\n", "\n", "\n", "\u001b[1m> Entering new chain...\u001b[0m\n", "What is the hometown of the reigning men's U.S. Open champion?\n", "Are follow up questions needed here:\u001b[32;1m\u001b[1;3m Yes.\n", "Follow up: Who is the reigning men's U.S. Open champion?\u001b[0m\n", "Intermediate answer: \u001b[33;1m\u001b[1;3mCarlos Alcaraz.\u001b[0m\u001b[32;1m\u001b[1;3m\n", "So the final answer is:\n", "\n", "Carlos Alcaraz\u001b[0m\n", "\u001b[1m> Finished chain.\u001b[0m\n", "\u001b[33;1m\u001b[1;3m\n", "So the final answer is:\n", "\n", "Carlos Alcaraz\u001b[0m\n", "\n"]}], "source": ["model_lab.compare(\"What is the hometown of the reigning men's U.S. Open champion?\")"]}, {"cell_type": "code", "execution_count": null, "id": "94159131", "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.9"}}, "nbformat": 4, "nbformat_minor": 5}