---
sidebar_position: 1.5
title: ä½¿ç”¨ LangChain è¿›è¡Œæµå¼å¤„ç†
---
# ä½¿ç”¨ LangChain è¿›è¡Œæµå¼å¤„ç†

æµå¼å¤„ç†å¯¹äºåŸºäº LLM çš„åº”ç”¨ç¨‹åºå¯¹æœ€ç»ˆç”¨æˆ·çš„å“åº”è‡³å…³é‡è¦ã€‚

é‡è¦çš„ LangChain åŸè¯­ï¼Œå¦‚ LLMsã€è§£æå™¨ã€æç¤ºã€æ£€ç´¢å™¨å’Œä»£ç†å®ç°äº† LangChain [Runnable æ¥å£](/docs/expression_language/interface)ã€‚

è¯¥æ¥å£æä¾›äº†ä¸¤ç§å¸¸è§çš„æµå¼å†…å®¹çš„æ–¹æ³•ï¼š

1. sync `stream` å’Œ async `astream`ï¼šæµå¼å¤„ç†çš„**é»˜è®¤å®ç°**ï¼Œä»é“¾ä¸­æµå¼ä¼ è¾“**æœ€ç»ˆè¾“å‡º**ã€‚
2. async `astream_events` å’Œ async `astream_log`ï¼šè¿™äº›æ–¹æ³•æä¾›äº†ä¸€ç§ä»é“¾ä¸­æµå¼ä¼ è¾“**ä¸­é—´æ­¥éª¤**å’Œ**æœ€ç»ˆè¾“å‡º**çš„æ–¹å¼ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹è¿™ä¸¤ç§æ–¹æ³•ï¼Œå¹¶å°è¯•äº†è§£å¦‚ä½•ä½¿ç”¨å®ƒä»¬ã€‚ ğŸ¥·

## ä½¿ç”¨ Stream

æ‰€æœ‰`Runnable`å¯¹è±¡éƒ½å®ç°äº†ä¸€ä¸ªåä¸º`stream`çš„åŒæ­¥æ–¹æ³•å’Œä¸€ä¸ªåä¸º`astream`çš„å¼‚æ­¥å˜ä½“ã€‚

è¿™äº›æ–¹æ³•æ—¨åœ¨ä»¥å—çš„å½¢å¼æµå¼ä¼ è¾“æœ€ç»ˆè¾“å‡ºï¼Œåªè¦å¯ç”¨å°±ä¼šäº§ç”Ÿæ¯ä¸ªå—ã€‚

åªæœ‰åœ¨ç¨‹åºä¸­çš„æ‰€æœ‰æ­¥éª¤éƒ½çŸ¥é“å¦‚ä½•å¤„ç†**è¾“å…¥æµ**æ—¶ï¼Œå³ä¸€æ¬¡å¤„ç†ä¸€ä¸ªè¾“å…¥å—ï¼Œå¹¶ç”Ÿæˆç›¸åº”çš„è¾“å‡ºå—æ—¶ï¼Œæ‰èƒ½è¿›è¡Œæµå¼å¤„ç†ã€‚

è¿™ç§å¤„ç†çš„å¤æ‚ç¨‹åº¦å¯ä»¥æœ‰æ‰€ä¸åŒï¼Œä»åƒå‘å‡ºç”± LLM ç”Ÿæˆçš„ä»¤ç‰Œè¿™æ ·çš„ç®€å•ä»»åŠ¡ï¼Œåˆ°åœ¨æ•´ä¸ª JSON å®Œæˆä¹‹å‰æµå¼ä¼ è¾“ JSON ç»“æœçš„æ›´å…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚

å¼€å§‹æ¢ç´¢æµå¼å¤„ç†çš„æœ€ä½³åœ°ç‚¹æ˜¯ä¸ LLM åº”ç”¨ç¨‹åºä¸­æœ€é‡è¦çš„ç»„ä»¶ä¹‹ä¸€ -- LLMs æœ¬èº«ï¼

### LLMs å’Œ Chat Models

å¤§å‹è¯­è¨€æ¨¡å‹åŠå…¶èŠå¤©å˜ä½“æ˜¯åŸºäº LLM çš„åº”ç”¨ç¨‹åºçš„ä¸»è¦ç“¶é¢ˆã€‚ğŸ™Š

å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆå¯¹æŸ¥è¯¢çš„å®Œæ•´å“åº”å¯èƒ½éœ€è¦**å‡ ç§’é’Ÿ**ã€‚è¿™è¿œè¿œæ…¢äºåº”ç”¨ç¨‹åºå¯¹æœ€ç»ˆç”¨æˆ·å“åº”æ„Ÿè§‰çµæ•çš„**~200-300 ms**çš„é˜ˆå€¼ã€‚

ä½¿åº”ç”¨ç¨‹åºæ„Ÿè§‰æ›´çµæ•çš„å…³é”®ç­–ç•¥æ˜¯æ˜¾ç¤ºä¸­é—´è¿›åº¦ï¼›ä¾‹å¦‚ï¼Œé€ä¸ªä»¤ç‰Œä»æ¨¡å‹ä¸­æµå¼ä¼ è¾“è¾“å‡ºã€‚

```python
# ä½¿ç”¨äººç±»è®ºç¤ºä¾‹ï¼Œä½†æ‚¨å¯ä»¥ä½¿ç”¨æ‚¨å–œæ¬¢çš„èŠå¤©æ¨¡å‹ï¼
from langchain.chat_models import ChatAnthropic

model = ChatAnthropic()

chunks = []
async for chunk in model.astream("ä½ å¥½ã€‚å‘Šè¯‰æˆ‘ä¸€äº›å…³äºä½ è‡ªå·±çš„äº‹æƒ…"):
    chunks.append(chunk)
    print(chunk.content, end="|", flush=True)
```

     ä½ å¥½|!| æˆ‘| çš„åå­—| æ˜¯| å…‹åŠ³å¾·|ã€‚| æˆ‘| æ˜¯|ä¸€ä¸ª|ç”±|äººç±»|åˆ›å»º|çš„|AI|åŠ©æ‰‹|ï¼Œ|æ—¨åœ¨|æœ‰æ‰€å¸®åŠ©|ã€|æ— å®³|å’Œ|è¯šå®|ã€‚||

è®©æˆ‘ä»¬æ£€æŸ¥å…¶ä¸­ä¸€ä¸ªå—


```python
chunks[0]
```




    AIMessageChunk(content=' ä½ å¥½')



æˆ‘ä»¬å¾—åˆ°äº†ä¸€ä¸ªå«åš `AIMessageChunk` çš„ä¸œè¥¿ã€‚è¿™ä¸ªå—ä»£è¡¨äº†ä¸€ä¸ª `AIMessage` çš„ä¸€éƒ¨åˆ†ã€‚

æ¶ˆæ¯å—æ˜¯å¯ä»¥æ·»åŠ çš„ -- å¯ä»¥ç®€å•åœ°å°†å®ƒä»¬ç›¸åŠ ä»¥è·å¾—åˆ°ç›®å‰ä¸ºæ­¢å“åº”çš„çŠ¶æ€ï¼


```python
chunks[0] + chunks[1] + chunks[2] + chunks[3] + chunks[4]
```




    AIMessageChunk(content=' ä½ å¥½! æˆ‘çš„åå­—æ˜¯')



### é“¾

å‡ ä¹æ‰€æœ‰çš„ LLM åº”ç”¨éƒ½æ¶‰åŠåˆ°ä¸æ­¢ä¸€ä¸ªè°ƒç”¨è¯­è¨€æ¨¡å‹çš„æ­¥éª¤ã€‚

è®©æˆ‘ä»¬ä½¿ç”¨ `LangChain è¡¨è¾¾è¯­è¨€` (`LCEL`) åˆ›å»ºä¸€ä¸ªç®€å•çš„é“¾ï¼Œå®ƒç»“åˆäº†ä¸€ä¸ªæç¤ºã€æ¨¡å‹å’Œä¸€ä¸ªè§£æå™¨ï¼Œå¹¶éªŒè¯äº†æµå¼å¤„ç†æ˜¯å¦æœ‰æ•ˆã€‚

æˆ‘ä»¬å°†ä½¿ç”¨ `StrOutputParser` æ¥è§£ææ¨¡å‹çš„è¾“å‡ºã€‚è¿™æ˜¯ä¸€ä¸ªç®€å•çš„è§£æå™¨ï¼Œä» `AIMessageChunk` ä¸­æå– `content` å­—æ®µï¼Œç»™æˆ‘ä»¬æ¨¡å‹è¿”å›çš„ `token`ã€‚

:::{.callout-tip}
LCEL æ˜¯ä¸€ç§é€šè¿‡å°†ä¸åŒçš„ LangChain åŸè¯­é“¾æ¥åœ¨ä¸€èµ·æ¥æŒ‡å®šâ€œç¨‹åºâ€çš„ *å£°æ˜æ€§* æ–¹æ³•ã€‚ä½¿ç”¨ LCEL åˆ›å»ºçš„é“¾å—ç›Šäº `stream` å’Œ `astream` çš„è‡ªåŠ¨å®ç°ï¼Œå…è®¸æµå¼ä¼ è¾“æœ€ç»ˆè¾“å‡ºã€‚äº‹å®ä¸Šï¼Œä½¿ç”¨ LCEL åˆ›å»ºçš„é“¾å®ç°äº†æ•´ä¸ªæ ‡å‡† Runnable æ¥å£ã€‚
:::


```python
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate

prompt = ChatPromptTemplate.from_template("å‘Šè¯‰æˆ‘ä¸€ä¸ªå…³äº {topic} çš„ç¬‘è¯")
parser = StrOutputParser()
chain = prompt | model | parser

async for chunk in chain.astream({"topic": "é¹¦é¹‰"}):
    print(chunk, end="|", flush=True)
```

     è¿™æ˜¯|ä¸€ä¸ª|å…³äº|ä¸€åª|é¹¦é¹‰|çš„|æ„šè ¢|çš„|ç¬‘è¯|:|
    
    ä»€ä¹ˆ|æ ·|çš„|è€å¸ˆ|ä¼š|ç»™å‡º|å¥½|å»ºè®®|?| ä¸€ä¸ª|çˆ¶æ¯|äº²(æ‹¬å¼§)| ä¸€ä¸ª|!||

:::{.callout-note}
æ‚¨ä¸å¿…ä½¿ç”¨ `LangChain è¡¨è¾¾è¯­è¨€` æ¥ä½¿ç”¨ LangChainï¼Œæ‚¨å¯ä»¥ä¾èµ–äºæ ‡å‡†çš„ **å‘½ä»¤å¼** ç¼–ç¨‹æ–¹æ³•ï¼Œé€šè¿‡åœ¨æ¯ä¸ªç»„ä»¶ä¸Šåˆ†åˆ«è°ƒç”¨ `invoke`ã€`batch` æˆ– `stream`ï¼Œå°†ç»“æœåˆ†é…ç»™å˜é‡ï¼Œç„¶åæ ¹æ®éœ€è¦åœ¨ä¸‹æ¸¸ä½¿ç”¨å®ƒä»¬ã€‚

å¦‚æœè¿™ç¬¦åˆæ‚¨çš„éœ€æ±‚ï¼Œé‚£ä¹ˆå¯¹æˆ‘ä»¬æ¥è¯´ä¹Ÿæ˜¯å¯ä»¥çš„ ğŸ‘Œï¼
:::

### ä½¿ç”¨è¾“å…¥æµ

å¦‚æœæ‚¨æƒ³è¦åœ¨ç”Ÿæˆæ—¶ä»è¾“å‡ºä¸­æµå¼ä¼ è¾“ JSON æ€ä¹ˆåŠï¼Ÿ

å¦‚æœæ‚¨ä¾èµ–äº `json.loads` æ¥è§£æéƒ¨åˆ† jsonï¼Œé‚£ä¹ˆè§£æå°†å¤±è´¥ï¼Œå› ä¸ºéƒ¨åˆ† json ä¸ä¼šæ˜¯æœ‰æ•ˆçš„ jsonã€‚

æ‚¨å¯èƒ½å®Œå…¨ä¸çŸ¥é“è¯¥åšä»€ä¹ˆ

ï¼Œå¹¶å£°ç§°æ— æ³•æµå¼ä¼ è¾“ JSONã€‚

äº‹å®ä¸Šï¼Œæœ‰ä¸€ç§æ–¹æ³•å¯ä»¥åšåˆ° -- è§£æå™¨éœ€è¦æ“ä½œ**è¾“å…¥æµ**ï¼Œå¹¶å°è¯•å°†éƒ¨åˆ† json â€œè‡ªåŠ¨å®Œæˆâ€ä¸ºæœ‰æ•ˆçŠ¶æ€ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹è¿™æ ·çš„è§£æå™¨å¦‚ä½•è¿ä½œï¼Œä»¥ç†è§£å…¶å«ä¹‰ã€‚


```python
from langchain_core.output_parsers import JsonOutputParser

chain = (
    model | JsonOutputParser()
)  # ç”±äº Langchain æ—§ç‰ˆæœ¬ä¸­çš„ä¸€ä¸ªé”™è¯¯ï¼ŒJsonOutputParser æœªèƒ½ä»æŸäº›æ¨¡å‹ä¸­æµå¼ä¼ è¾“ç»“æœ
async for text in chain.astream(
    'ä»¥ JSON æ ¼å¼è¾“å‡ºæ³•å›½ã€è¥¿ç­ç‰™å’Œæ—¥æœ¬çš„å›½å®¶åŠå…¶äººå£çš„åˆ—è¡¨ã€‚ä½¿ç”¨ä¸€ä¸ªå¸¦æœ‰â€œcountriesâ€å¤–é”®çš„å­—å…¸ï¼Œå…¶ä¸­åŒ…å«ä¸€ä¸ªå›½å®¶åˆ—è¡¨ã€‚æ¯ä¸ªå›½å®¶åº”è¯¥æœ‰â€œnameâ€å’Œâ€œpopulationâ€å…³é”®å­—ã€‚'
):
    print(text, flush=True)
```

    {}
    {'countries': []}
    {'countries': [{}]}
    {'countries': [{'name': ''}]}
    {'countries': [{'name': 'æ³•å›½'}]}
    {'countries': [{'name': 'æ³•å›½', 'population': 67}]}
    {'countries': [{'name': 'æ³•å›½', 'population': 6739}]}
    {'countries': [{'name': 'æ³•å›½', 'population': 673915}]}
    {'countries': [{'name': 'æ³•å›½', 'population': 67391582}]}
    {'countries': [{'name': 'æ³•å›½', 'population': 67391582}, {}]}
    {'countries': [{'name': 'æ³•å›½', 'population': 67391582}, {'name': ''}]}
    {'countries': [{'name': 'æ³•å›½', 'population': 67391582}, {'name': 'è¥¿'}]}
    {'countries': [{'name': 'æ³•å›½', 'population': 67391582}, {'name': 'è¥¿ç­ç‰™'}]}
    {'countries': [{'name': 'æ³•å›½', 'population': 67391582}, {'name': 'è¥¿ç­ç‰™', 'population': 46}]}
    {'countries': [{'name': 'æ³•å›½', 'population': 67391582}, {'name': 'è¥¿ç­ç‰™', 'population': 4675}]}
    {'countries': [{'name': 'æ³•å›½', 'population': 67391582}, {'name': 'è¥¿ç­ç‰™', 'population': 467547}]}
    {'countries': [{'name': 'æ³•å›½', 'population': 67391582}, {'name': 'è¥¿ç­ç‰™', 'population': 46754778}]}
    {'countries': [{'name': 'æ³•å›½', 'population': 67391582}, {'name': 'è¥¿ç­ç‰™', 'population': 46754778}, {}]}
    {'countries': [{'name': 'æ³•å›½', 'population': 67391582}, {'name': 'è¥¿ç­ç‰™', 'population': 46754778}, {'name': ''}]}
    {'countries': [{'name': 'æ³•å›½', 'population': 67391582}, {'name': 'è¥¿ç­ç‰™', 'population': 46754778}, {'name': 'æ—¥æœ¬'}]}
    {'countries': [{'name': 'æ³•å›½', 'population': 67391582}, {'name': 'è¥¿ç­ç‰™', 'population': 46754778}, {'name': 'æ—¥æœ¬', 'population': 12}]}
    {'countries': [{'name': 'æ³•å›½', 'population': 67391582}, {'name': 'è¥¿ç­ç‰™', 'population': 46754778}, {'name': 'æ—¥æœ¬', 'population': 12647}]}
    {'countries': [{'name': 'æ³•å›½', 'population': 67391582}, {'name': 'è¥¿ç­ç‰™', 'population': 46754778}, {'name': 'æ—¥æœ¬', 'population': 1264764}]}
    {'countries': [{'name': 'æ³•å›½', 'population': 67391582}, {'name': 'è¥¿ç­ç‰™', 'population': 46754778}, {'name': 'æ—¥æœ¬', 'population': 126476461}]}
    

ç°åœ¨ï¼Œè®©æˆ‘ä»¬**ä¸­æ–­**æµå¼ä¼ è¾“ã€‚æˆ‘ä»¬å°†ä½¿ç”¨å…ˆå‰çš„ç¤ºä¾‹ï¼Œå¹¶åœ¨æœ«å°¾é™„åŠ ä¸€ä¸ªæå–å‡½æ•°ï¼Œè¯¥å‡½æ•°ä»æœ€ç»ˆçš„ JSON ä¸­æå–å›½å®¶åç§°ã€‚

:::{.callout-warning}
é“¾ä¸­çš„ä»»ä½•æ­¥éª¤ï¼Œå¦‚æœæ“ä½œçš„æ˜¯**æœ€ç»ˆè¾“å…¥**è€Œä¸æ˜¯**è¾“å…¥æµ**ï¼Œéƒ½å¯èƒ½é€šè¿‡ `stream` æˆ– `astream` æ‰“ç ´æµå¼ä¼ è¾“åŠŸèƒ½ã€‚
:::

:::{.callout-tip}
ç¨åï¼Œæˆ‘ä»¬å°†è®¨è®º `astream_events` APIï¼Œè¯¥ API å°†æµå¼ä¼ è¾“ä¸­é—´æ­¥éª¤çš„ç»“æœã€‚å³ä½¿é“¾ä¸­åŒ…å«ä»…æ“ä½œ**æœ€ç»ˆè¾“å…¥**è€Œä¸æ˜¯**è¾“å…¥æµ**çš„æ­¥éª¤ï¼Œè¯¥ API ä¹Ÿä¼šæµå¼ä¼ è¾“ç»“æœã€‚
:::


```python
from langchain_core.output_parsers import (
    JsonOutputParser,
)


# ä¸€ä¸ªæ“ä½œæœ€ç»ˆè¾“å…¥è€Œä¸æ˜¯è¾“å…¥æµçš„å‡½æ•°
def _extract_country_names(inputs):
    """ä¸€ä¸ªä¸æ“ä½œè¾“å…¥æµå¹¶ä¸”ä¼šä¸­æ–­æµå¼ä¼ è¾“çš„å‡½æ•°ã€‚"""
    if not isinstance(inputs, dict):
        return ""

    if "countries" not in inputs:
        return ""

    countries = inputs["countries"]

    if not isinstance(countries, list):
        return ""

    country_names = [
        country.get("name") for country in countries if isinstance(country, dict)
    ]
    return country_names


chain = model | JsonOutputParser() | _extract_country_names

async for text in chain.astream(
    'ä»¥ JSON æ ¼å¼è¾“å‡ºæ³•å›½ã€è¥¿ç­ç‰™å’Œæ—¥æœ¬çš„å›½å®¶åŠå…¶äººå£çš„åˆ—è¡¨ã€‚ä½¿ç”¨ä¸€ä¸ªå¸¦æœ‰â€œcountriesâ€å¤–é”®çš„å­—å…¸ï¼Œå…¶ä¸­åŒ…å«ä¸€ä¸ªå›½å®¶åˆ—è¡¨ã€‚æ¯ä¸ªå›½å®¶åº”è¯¥æœ‰â€œnameâ€å’Œâ€œpopulationâ€å…³é”®å­—ã€‚'
):
    print(text, end="|", flush=True)
```

    ['æ³•å›½', 'è¥¿ç­ç‰™', 'æ—¥æœ¬']|

### ç”Ÿæˆå™¨å‡½æ•°

è®©æˆ‘ä»¬ä½¿ç”¨å¯ä»¥æ“ä½œ**è¾“å…¥æµ**çš„ç”Ÿæˆå™¨å‡½æ•°æ¥ä¿®å¤æµå¼å¤„ç†ã€‚

:::{.callout-tip}
ç”Ÿæˆå™¨å‡½æ•°ï¼ˆä½¿ç”¨ `yield` çš„å‡½æ•°ï¼‰å…è®¸ç¼–å†™èƒ½å¤Ÿæ“ä½œ**è¾“å…¥æµ**çš„ä»£ç ã€‚
:::

```python
from langchain_core.output_parsers import JsonOutputParser


async def _extract_country_names_streaming(input_stream):
    """A function that operates on input streams."""
    country_names_so_far = set()

    async for input in input_stream:
        if not isinstance(input, dict):
            continue

        if "countries" not in input:
            continue

        countries = input["countries"]

        if not isinstance(countries, list):
            continue

        for country in countries:
            name = country.get("name")
            if not name:
                continue
            if name not in country_names_so_far:
                yield name
                country_names_so_far.add(name)


chain = model | JsonOutputParser() | _extract_country_names_streaming

async for text in chain.astream(
    'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of "countries" which contains a list of countries. Each country should have the key `name` and `population`'
):
    print(text, end="|", flush=True)
```

    France|Sp|Spain|Japan|

:::{.callout-note}
å› ä¸ºä¸Šé¢çš„ä»£ç ä¾èµ–äº JSON è‡ªåŠ¨è¡¥å…¨ï¼Œæ‚¨å¯èƒ½ä¼šçœ‹åˆ°éƒ¨åˆ†å›½å®¶åç§°ï¼ˆä¾‹å¦‚ï¼Œ`Sp` å’Œ `Spain`ï¼‰ï¼Œè¿™ä¸æ˜¯æˆ‘ä»¬å¯¹æå–ç»“æœçš„æœŸæœ›ï¼

æˆ‘ä»¬å…³æ³¨çš„æ˜¯æµå¼å¤„ç†çš„æ¦‚å¿µï¼Œè€Œä¸ä¸€å®šæ˜¯é“¾çš„ç»“æœã€‚
:::

### éæµå¼ç»„ä»¶

ä¸€äº›å†…ç½®ç»„ä»¶ï¼Œå¦‚æ£€ç´¢å™¨ï¼Œä¸æä¾›ä»»ä½• `streaming`ã€‚å¦‚æœæˆ‘ä»¬å°è¯•å¯¹å®ƒä»¬è¿›è¡Œ`stream`ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ ğŸ¤¨

```python
from langchain_community.vectorstores import FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import OpenAIEmbeddings

template = """Answer the question based only on the following context:
{context}

Question: {question}
"""
prompt = ChatPromptTemplate.from_template(template)

vectorstore = FAISS.from_texts(
    ["harrison worked at kensho", "harrison likes spicy food"],
    embedding=OpenAIEmbeddings(),
)
retriever = vectorstore.as_retriever()

chunks = [chunk for chunk in retriever.stream("where did harrison work?")]
chunks
```

åªæœ‰ä»è¯¥ç»„ä»¶äº§ç”Ÿçš„æœ€ç»ˆç»“æœè¢«æµå¼ä¼ è¾“äº†ã€‚

è¿™æ˜¯å¯ä»¥æ¥å—çš„ ğŸ¥¹ï¼ å¹¶ä¸æ˜¯æ‰€æœ‰ç»„ä»¶éƒ½å¿…é¡»å®ç°æµå¼ä¼ è¾“ -- åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæµå¼ä¼ è¾“è¦ä¹ˆæ˜¯ä¸å¿…è¦çš„ã€å›°éš¾çš„ï¼Œè¦ä¹ˆæ ¹æœ¬æ²¡æœ‰æ„ä¹‰ã€‚

:::{.callout-tip}
ä½¿ç”¨éæµå¼ç»„ä»¶æ„å»ºçš„ LCEL é“¾ï¼Œåœ¨è®¸å¤šæƒ…å†µä¸‹ä»ç„¶èƒ½å¤Ÿè¿›è¡Œæµå¼ä¼ è¾“ï¼Œéƒ¨åˆ†è¾“å‡ºçš„æµå¼ä¼ è¾“ä»é“¾ä¸­æœ€åä¸€ä¸ªéæµå¼æ­¥éª¤ä¹‹åå¼€å§‹ã€‚
:::

```python
retrieval_chain = (
    {
        "context": retriever.with_config(run_name="Docs"),
        "question": RunnablePassthrough(),
    }
    | prompt
    | model
    | StrOutputParser()
)
```


```python
for chunk in retrieval_chain.stream(
    "Where did harrison work? " "Write 3 made up sentences about this place."
):
    print(chunk, end="|", flush=True)
```

     Based| on| the| given| context|,| the| only| information| provided| about| where| Harrison| worked| is| that| he| worked| at| Ken|sh|o|.| Since| there| are| no| other| details| provided| about| Ken|sh|o|,| I| do| not| have| enough| information| to| write| 3| additional| made| up| sentences| about| this| place|.| I| can| only| state| that| Harrison| worked| at| Ken|sh|o|.||

ç°åœ¨æˆ‘ä»¬å·²ç»äº†è§£äº† `stream` å’Œ `astream` çš„å·¥ä½œåŸç†ï¼Œè®©æˆ‘ä»¬è¿›å…¥æµå¼äº‹ä»¶çš„ä¸–ç•Œ ğŸï¸ã€‚

## ä½¿ç”¨æµäº‹ä»¶

äº‹ä»¶æµæ˜¯ä¸€ä¸ª**beta** APIã€‚è¯¥ APIå¯èƒ½ä¼šæ ¹æ®åé¦ˆåšå‡ºä¸€äº›æ›´æ”¹ã€‚

:::{.callout-note}
å¼•å…¥äº langchain-core **0.1.14** ç‰ˆæœ¬ã€‚
:::


```python
import langchain_core

langchain_core.__version__
```




    '0.1.18'



ä¸ºäº†è®© `astream_events` API æ­£å¸¸å·¥ä½œï¼š

* å°½å¯èƒ½åœ¨ä»£ç ä¸­ä½¿ç”¨ `async`ï¼ˆä¾‹å¦‚ï¼Œå¼‚æ­¥å·¥å…·ç­‰ï¼‰
* å¦‚æœå®šä¹‰è‡ªå®šä¹‰å‡½æ•°/å¯è¿è¡Œå¯¹è±¡ï¼Œè¯·ä¼ æ’­å›è°ƒ
* æ¯å½“ä½¿ç”¨é LCEL çš„å¯è¿è¡Œå¯¹è±¡æ—¶ï¼Œè¯·ç¡®ä¿åœ¨ LLM ä¸Šè°ƒç”¨ `.astream()` è€Œä¸æ˜¯ `.ainvoke`ï¼Œä»¥å¼ºåˆ¶ LLM æµå¼ä¼ è¾“ä»¤ç‰Œã€‚
* å¦‚æœæœ‰ä»»ä½•ä¸ç¬¦åˆé¢„æœŸçš„æƒ…å†µï¼Œè¯·å‘Šè¯‰æˆ‘ä»¬ï¼ :)

### äº‹ä»¶å‚è€ƒ

ä¸‹é¢æ˜¯ä¸€ä¸ªå‚è€ƒè¡¨ï¼Œæ˜¾ç¤ºå„ç§ Runnable å¯¹è±¡å¯èƒ½äº§ç”Ÿçš„ä¸€äº›äº‹ä»¶ã€‚


:::{.callout-note}
å½“æµå¼ä¼ è¾“æ­£ç¡®å®ç°æ—¶ï¼Œå¯¹äºå¯è¿è¡Œå¯¹è±¡æ¥è¯´ï¼Œç›´åˆ°å®Œå…¨æ¶ˆè€—äº†è¾“å…¥æµä¹‹åæ‰ä¼šçŸ¥é“è¾“å…¥ã€‚è¿™æ„å‘³ç€ `inputs` é€šå¸¸ä»…åŒ…å«åœ¨ `end` äº‹ä»¶ä¸­ï¼Œè€Œä¸æ˜¯åœ¨ `start` äº‹ä»¶ä¸­ã€‚
:::


| äº‹ä»¶                   | åç§°             | å—                             | è¾“å…¥                                         | è¾“å‡º                                           |
|----------------------|------------------|---------------------------------|-----------------------------------------------|-------------------------------------------------|
| on_chat_model_start  | [model name]     |                                 | {"messages": [[SystemMessage, HumanMessage]]} |                                                 |
| on_chat_model_stream | [model name]     | AIMessageChunk(content="hello") |                                               |                                                 |
| on_chat_model_end    | [model name]     |                                 | {"messages": [[SystemMessage, HumanMessage]]} | {"generations": [...], "llm_output": None, ...} |
| on_llm_start         | [model name]     |                                 | {'input': 'hello'}                            |                                                 |
| on_llm_stream        | [model name]     | 'Hello'                         |                                               |                                                 |
| on_llm_end           | [model name]     |                                 | 'Hello human!'                               

 |
| on_chain_start       | format_docs      |                                 |                                               |                                                 |
| on_chain_stream      | format_docs      | "hello world!, goodbye world!"  |                                               |                                                 |
| on_chain_end         | format_docs      |                                 | [Document(...)]                               | "hello world!, goodbye world!"                  |
| on_tool_start        | some_tool        |                                 | {"x": 1, "y": "2"}                            |                                                 |
| on_tool_stream       | some_tool        | {"x": 1, "y": "2"}              |                                               |                                                 |
| on_tool_end          | some_tool        |                                 |                                               | {"x": 1, "y": "2"}                              |
| on_retriever_start   | [retriever name] |                                 | {"query": "hello"}                            |                                                 |
| on_retriever_chunk   | [retriever name] | {documents: [...]}              |                                               |                                                 |
| on_retriever_end     | [retriever name] |                                 | {"query": "hello"}                            | {documents: [...]}                              |
| on_prompt_start      | [template_name]  |                                 | {"question": "hello"}                         |                                                 |
| on_prompt_end        | [template_name]  |                                 | {"question": "hello"}                         | ChatPromptValue(messages: [SystemMessage, ...]) |

### èŠå¤©æ¨¡å‹

è®©æˆ‘ä»¬é¦–å…ˆæŸ¥çœ‹èŠå¤©æ¨¡å‹äº§ç”Ÿçš„äº‹ä»¶ã€‚


```python
events = []
async for event in model.astream_events("hello", version="v1"):
    events.append(event)
```

    /home/eugene/src/langchain/libs/core/langchain_core/_api/beta_decorator.py:86: LangChainBetaWarning: This API is in beta and may change in the future.
      warn_beta(
    

:::{.callout-note}

å˜¿ï¼ŒAPI ä¸­é‚£ä¸ªå¥‡æ€ªçš„ `version="v1"` å‚æ•°æ˜¯ä»€ä¹ˆï¼Ÿï¼ ğŸ˜¾

è¿™æ˜¯ä¸€ä¸ª**beta API**ï¼Œæˆ‘ä»¬å‡ ä¹è‚¯å®šä¼šå¯¹å…¶è¿›è¡Œä¸€äº›æ›´æ”¹ã€‚

è¯¥ç‰ˆæœ¬å‚æ•°å°†å…è®¸æˆ‘ä»¬æœ€å°åŒ–å¯¹æ‚¨ä»£ç çš„æ­¤ç±»æ›´æ”¹ã€‚

ç®€è€Œè¨€ä¹‹ï¼Œæˆ‘ä»¬ç°åœ¨è®©æ‚¨æ„Ÿåˆ°æ¼ç«ï¼Œä»¥ä¾¿ä»¥åä¸å¿…è®©æ‚¨æ„Ÿåˆ°æ¼ç«ã€‚
:::

è®©æˆ‘ä»¬çœ‹ä¸€çœ‹å¼€å§‹äº‹ä»¶å’Œç»“æŸäº‹ä»¶ä¸­çš„ä¸€äº›å†…å®¹ã€‚


```python
events[:3]
```




    [{'event': 'on_chat_model_start',
      'run_id': '555843ed-3d24-4774-af25-fbf030d5e8c4',
      'name': 'ChatAnthropic',
      'tags': [],
      'metadata': {},
      'data': {'input': 'hello'}},
     {'event': 'on_chat_model_stream',
      'run_id': '555843ed-3d24-4774-af25-fbf030d5e8c4',
      'tags': [],
      'metadata': {},
      'name': 'ChatAnthropic',
      'data': {'chunk': AIMessageChunk(content=' Hello')}},
     {'event': 'on_chat_model_stream',
      'run_id': '555843ed-3d24-4774-af25-fbf030d5e8c4',
      'tags': [],
      'metadata': {},
      'name': 'ChatAnthropic',
      'data': {'chunk': AIMessageChunk(content='!')}}]




```python
events[-2:]
```




    [{'event': 'on_chat_model_stream',
      'run_id': '555843ed-3d24-4774-af25-fbf030d5e8c4',
      'tags': [],
      'metadata': {},
      'name': 'ChatAnthropic',
      'data': {'chunk': AIMessageChunk(content='')}},
     {'event': 'on_chat_model_end',
      'name': 'ChatAnthropic',
      'run_id': '555843ed-3d24-4774-af25-fbf030d5e8c4',
      'tags': [],
      'metadata': {},
      'data': {'output': AIMessageChunk(content=' Hello!')}}]



### é“¾

è®©æˆ‘ä»¬å›é¡¾ä¸€ä¸‹è§£ææµå¼JSONçš„ç¤ºä¾‹é“¾ï¼Œä»¥æ¢ç´¢æµå¼äº‹ä»¶APIã€‚

```python
chain = (
    model | JsonOutputParser()
)  # ç”±äºè¾ƒæ—§ç‰ˆæœ¬çš„Langchainä¸­å­˜åœ¨é”™è¯¯ï¼ŒJsonOutputParseræ— æ³•ä»æŸäº›æ¨¡å‹ä¸­æµå¼ä¼ è¾“ç»“æœ

events = [
    event
    async for event in chain.astream_events(
        'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of "countries" which contains a list of countries. Each country should have the key `name` and `population`',
        version="v1",
    )
]
```

å¦‚æœä½ æ£€æŸ¥å‰å‡ ä¸ªäº‹ä»¶ï¼Œä½ ä¼šæ³¨æ„åˆ°æœ‰**3**ä¸ªä¸åŒçš„å¼€å§‹äº‹ä»¶ï¼Œè€Œä¸æ˜¯**2**ä¸ªå¼€å§‹äº‹ä»¶ã€‚

è¿™ä¸‰ä¸ªå¼€å§‹äº‹ä»¶å¯¹åº”äºï¼š

1. é“¾ï¼ˆæ¨¡å‹ + è§£æå™¨ï¼‰
2. æ¨¡å‹
3. è§£æå™¨

```python
events[:3]
```

ä½ è®¤ä¸ºå¦‚æœä½ æŸ¥çœ‹æœ€å3ä¸ªäº‹ä»¶ä¼šçœ‹åˆ°ä»€ä¹ˆï¼Ÿä¸­é—´çš„äº‹ä»¶å‘¢ï¼Ÿ

è®©æˆ‘ä»¬ä½¿ç”¨è¿™ä¸ªAPIæ¥è¾“å‡ºæ¨¡å‹å’Œè§£æå™¨çš„æµäº‹ä»¶ã€‚æˆ‘ä»¬å¿½ç•¥é“¾ä¸­çš„å¼€å§‹äº‹ä»¶ã€ç»“æŸäº‹ä»¶å’Œäº‹ä»¶ã€‚

```python
num_events = 0

async for event in chain.astream_events(
    'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of "countries" which contains a list of countries. Each country should have the key `name` and `population`',
    version="v1",
):
    kind = event["event"]
    if kind == "on_chat_model_stream":
        print(
            f"Chat model chunk: {repr(event['data']['chunk'].content)}",
            flush=True,
        )
    if kind == "on_parser_stream":
        print(f"Parser chunk: {event['data']['chunk']}", flush=True)
    num_events += 1
    if num_events > 30:
        # æˆªæ–­è¾“å‡º
        print("...")
        break
```

ç”±äºæ¨¡å‹å’Œè§£æå™¨éƒ½æ”¯æŒæµå¼ä¼ è¾“ï¼Œæˆ‘ä»¬å®æ—¶çœ‹åˆ°äº†ä¸¤ä¸ªç»„ä»¶çš„æµå¼äº‹ä»¶ï¼æŒºé…·çš„ï¼Œä¸æ˜¯å—ï¼ŸğŸ¦œ

### è¿‡æ»¤äº‹ä»¶

ç”±äºè¿™ä¸ªAPIäº§ç”Ÿäº†å¦‚æ­¤å¤šçš„äº‹ä»¶ï¼Œèƒ½å¤Ÿå¯¹äº‹ä»¶è¿›è¡Œè¿‡æ»¤æ˜¯å¾ˆæœ‰ç”¨çš„ã€‚

ä½ å¯ä»¥é€šè¿‡ç»„ä»¶çš„`name`ã€ç»„ä»¶çš„`tags`æˆ–ç»„ä»¶çš„`type`è¿›è¡Œè¿‡æ»¤ã€‚

#### é€šè¿‡åç§°

```python
chain = model.with_config({"run_name": "model"}) | JsonOutputParser().with_config(
    {"run_name": "my_parser"}
)

max_events = 0
async for event in chain.astream_events(
    'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of "countries" which contains a list of countries. Each country should have the key `name` and `population`',
    version="v1",
    include_names=["my_parser"],
):
    print(event)
    max_events += 1
    if max_events > 10:
        # æˆªæ–­è¾“å‡º
        print("...")
        break
```

#### é€šè¿‡ç±»å‹

```python
chain = model.with_config({"run_name": "model"}) | JsonOutputParser().with_config(
    {"run_name": "my_parser"}
)

max_events = 0
async for event in chain.astream_events(
    'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of "countries" which contains a list of countries. Each country should have the key `name` and `population`',
    version="v1",
    include_types=["chat_model"],
):
    print(event)
    max_events += 1
    if max_events > 10:
        # æˆªæ–­è¾“å‡º
        print("...")
        break
```

#### é€šè¿‡æ ‡ç­¾

:::{.callout-caution}

æ ‡ç­¾ä¼šè¢«ç»™å®šå¯è¿è¡Œç»„ä»¶çš„å­ç»„ä»¶ç»§æ‰¿ã€‚

å¦‚æœä½ ä½¿ç”¨æ ‡ç­¾è¿›è¡Œè¿‡æ»¤ï¼Œè¯·ç¡®ä¿è¿™æ˜¯ä½ æƒ³è¦çš„ã€‚
:::

```python
chain = (model | JsonOutputParser()).with_config({"tags": ["my_chain"]})

max_events = 0
async for event in chain.astream_events(
    'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of "countries" which contains a list of countries. Each country should have the key `name` and `population`',
    version="v1",
    include_tags=["my_chain"],
):
    print(event)
    max_events += 1
    if max_events > 10:
        # æˆªæ–­è¾“å‡º
        print("...")
        break
```

=======
# æˆªæ–­è¾“å‡º
print("...")
break

```

{'event': 'on_chain_start', 'run_id': '190875f3-3fb7-49ad-9b6e-f49da22f3e49', 'name': 'RunnableSequence', 'tags': ['my_chain'], 'metadata': {}, 'data': {'input': 'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of "countries" which contains a list of countries. Each country should have the key `name` and `population`'}}
{'event': 'on_chat_model_start', 'name': 'ChatAnthropic', 'run_id': 'ff58f732-b494-4ff9-852a-783d42f4455d', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {}, 'data': {'input': {'messages': [[HumanMessage(content='output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of "countries" which contains a list of countries. Each country should have the key `name` and `population`')]]}}}
{'event': 'on_parser_start', 'name': 'JsonOutputParser', 'run_id': '3b5e4ca1-40fe-4a02-9a19-ba2a43a6115c', 'tags': ['seq:step:2', 'my_chain'], 'metadata': {}, 'data': {}}
{'event': 'on_chat_model_stream', 'name': 'ChatAnthropic', 'run_id': 'ff58f732-b494-4ff9-852a-783d42f4455d', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {}, 'data': {'chunk': AIMessageChunk(content=' Here')}}
{'event': 'on_chat_model_stream', 'name': 'ChatAnthropic', 'run_id': 'ff58f732-b494-4ff9-852a-783d42f4455d', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {}, 'data': {'chunk': AIMessageChunk(content=' is')}}
{'event': 'on_chat_model_stream', 'name': 'ChatAnthropic', 'run_id': 'ff58f732-b494-4ff9-852a-783d42f4455d', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {}, 'data': {'chunk': AIMessageChunk(content=' the')}}
{'event': 'on_chat_model_stream', 'name': 'ChatAnthropic', 'run_id': 'ff58f732-b494-4ff9-852a-783d42f4455d', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {}, 'data': {'chunk': AIMessageChunk(content=' JSON')}}
{'event': 'on_chat_model_stream', 'name': 'ChatAnthropic', 'run_id': 'ff58f732-b494-4ff9-852a-783d42f4455d', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {}, 'data': {'chunk': AIMessageChunk(content=' with')}}
{'event': 'on_chat_model_stream', 'name': 'ChatAnthropic', 'run_id': 'ff58f732-b494-4ff9-852a-783d42f4455d', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {}, 'data': {'chunk': AIMessageChunk(content=' the')}}
{'event': 'on_chat_model_stream', 'name': 'ChatAnthropic', 'run_id': 'ff58f732-b494-4ff9-852a-783d42f4455d', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {}, 'data': {'chunk': AIMessageChunk(content=' requested')}}
{'event': 'on_chat_model_stream', 'name': 'ChatAnthropic', 'run_id': 'ff58f732-b494-4ff9-852a-783d42f4455d', 'tags': ['seq:step:1', 'my_chain'], 'metadata': {}, 'data': {'chunk': AIMessageChunk(content=' countries')}}
...

### éæµå¼ç»„ä»¶

è®°ä½ï¼Œæœ‰äº›ç»„ä»¶ä¸é€‚åˆæµå¼å¤„ç†ï¼Œå› ä¸ºå®ƒä»¬ä¸é€‚ç”¨äº**è¾“å…¥æµ**ã€‚

è™½ç„¶è¿™äº›ç»„ä»¶åœ¨ä½¿ç”¨`astream`æ—¶å¯èƒ½ä¼šä¸­æ–­æœ€ç»ˆè¾“å‡ºçš„æµå¼å¤„ç†ï¼Œä½†ä½¿ç”¨`astream_events`ä»ç„¶ä¼šä»æ”¯æŒæµå¼å¤„ç†çš„ä¸­é—´æ­¥éª¤ä¸­äº§ç”Ÿæµå¼äº‹ä»¶ï¼


```python
# ä¸æ”¯æŒæµå¼å¤„ç†çš„å‡½æ•°ã€‚
# å®ƒæ“ä½œçš„æ˜¯æœ€ç»ˆçš„è¾“å…¥ï¼Œè€Œä¸æ˜¯è¾“å…¥æµã€‚
def _extract_country_names(inputs):
    """ä¸æ”¯æŒæµå¼å¤„ç†çš„å‡½æ•°ï¼Œä¼šä¸­æ–­æµå¼å¤„ç†ã€‚"""
    if not isinstance(inputs, dict):
        return ""

    if "countries" not in inputs:
        return ""

    countries = inputs["countries"]

    if not isinstance(countries, list):
        return ""

    country_names = [
        country.get("name") for country in countries if isinstance(country, dict)
    ]
    return country_names


chain = (
    model | JsonOutputParser() | _extract_country_names
)  # è¿™ä¸ªè§£æå™¨ç›®å‰åªé€‚ç”¨äºOpenAI
```

æ­£å¦‚é¢„æœŸçš„é‚£æ ·ï¼Œ`astream` APIæ— æ³•æ­£å¸¸å·¥ä½œï¼Œå› ä¸º`_extract_country_names`ä¸é€‚ç”¨äºæµå¼å¤„ç†ã€‚


```python
async for chunk in chain.astream(
    'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of "countries" which contains a list of countries. Each country should have the key `name` and `population`',
):
    print(chunk, flush=True)
```

['France', 'Spain', 'Japan']
    

ç°åœ¨ï¼Œè®©æˆ‘ä»¬é€šè¿‡ä½¿ç”¨`astream_events`æ¥ç¡®è®¤æˆ‘ä»¬ä»ç„¶å¯ä»¥ä»æ¨¡å‹å’Œè§£æå™¨ä¸­çœ‹åˆ°æµå¼è¾“å‡ºã€‚


```python
num_events = 0

async for event in chain.astream_events(
    'output a list of the countries france, spain and japan and their populations in JSON format. Use a dict with an outer key of "countries" which contains a list of countries. Each country should have the key `name` and `population`',
    version="v1",
):
    kind = event["event"]
    if kind == "on_chat_model_stream":
        print(
            f"Chat model chunk: {repr(event['data']['chunk'].content)}",
            flush=True,
        )
    if kind == "on_parser_stream":
        print(f"Parser chunk: {event['data']['chunk']}", flush=True)
    num_events += 1
    if num_events > 30:
        # æˆªæ–­è¾“å‡º
        print("...")
        break
```

Chat model chunk: ' Here'
Chat model chunk: ' is'
Chat model chunk: ' the'
Chat model chunk: ' JSON'
Chat model chunk: ' with'
Chat model chunk: ' the'
Chat model chunk: ' requested'
Chat model chunk: ' countries'
Chat model chunk: ' and'
Chat model chunk: ' their'
Chat model chunk: ' populations'
Chat model chunk: ':'
Chat model chunk: '\n\n```'
Chat model chunk: 'json'
Parser chunk: {}
Chat model chunk: '\n{'
Chat model chunk: '\n '
Chat model chunk: ' "'
Chat model chunk: 'countries'
Chat model chunk: '":'
Parser chunk: {'countries': []}
Chat model chunk: ' ['
Chat model chunk: '\n   '
Parser chunk: {'countries': [{}]}
Chat model chunk: ' {'
Chat model chunk: '\n     '
Chat model chunk: ' "'
...

### ä¼ æ’­å›è°ƒ

:::{.callout-caution}
å¦‚æœåœ¨å·¥å…·ä¸­è°ƒç”¨å¯è¿è¡Œå¯¹è±¡ï¼Œè¯·å°†å›è°ƒä¼ æ’­ç»™å¯è¿è¡Œå¯¹è±¡ï¼›å¦åˆ™ï¼Œå°†ä¸ä¼šç”Ÿæˆæµå¼äº‹ä»¶ã€‚
:::

:::{.callout-note}
å½“ä½¿ç”¨RunnableLambdasæˆ–@chainè£…é¥°å™¨æ—¶ï¼Œå›è°ƒä¼šåœ¨å¹•åè‡ªåŠ¨ä¼ æ’­ã€‚
:::


```python
from langchain_core.runnables import RunnableLambda
from langchain_core.tools import tool


def reverse_word(word: str):
    return word[::-1]


reverse_word = RunnableLambda(reverse_word)


@tool
def bad_tool(word: str):
    """ä¸ä¼ æ’­å›è°ƒçš„è‡ªå®šä¹‰å·¥å…·ã€‚"""
    return reverse_word.invoke(word)


async for event in bad_tool.astream_events("hello", version="v1"):
    print(event)
```

{'event': 'on_tool_start', 'run_id': 'ae7690f8-ebc9-4886-9bbe-cb336ff274f2', 'name': 'bad_tool', 'tags': [], 'metadata': {}, 'data': {'input': 'hello'}}
{'event': 'on_tool_stream', 'run_id': 'ae7690f8-ebc9-4886-9bbe-cb336ff274f2', 'tags': [], 'metadata': {}, 'name': 'bad_tool', 'data': {'chunk': 'olleh'}}
{'event': 'on_tool_end', 'name': 'bad_tool', 'run_id': 'ae7690f8-ebc9-4886-9bbe-cb336ff274f2', 'tags': [], 'metadata': {}, 'data': {'output': 'olleh'}}
    

è¿™æ˜¯ä¸€ä¸ªæ­£ç¡®ä¼ æ’­å›è°ƒçš„é‡æ–°å®ç°ã€‚ç°åœ¨ä½ ä¼šæ³¨æ„åˆ°æˆ‘ä»¬ä»`reverse_word`å¯è¿è¡Œå¯¹è±¡ä¸­ä¹Ÿå¾—åˆ°äº†äº‹ä»¶ã€‚


```python
@tool
def correct_tool(word: str, callbacks):
    """æ­£ç¡®ä¼ æ’­å›è°ƒçš„å·¥å…·ã€‚"""
    return reverse_word.invoke(word, {"callbacks": callbacks})


async for event in correct_tool.astream_events("hello", version="v1"):
    print(event)
```

{'event': 'on_tool_start', 'run_id': '384f1710-612e-4022-a6d4-8a7bb0cc757e', 'name': 'correct_tool', 'tags': [], 'metadata': {}, 'data': {'input': 'hello'}}
{'event': 'on_chain_start', 'name': 'reverse_word', 'run_id': 'c4882303-8867-4dff-b031-7d9499b39dda', 'tags': [], 'metadata': {}, 'data': {'input': 'hello'}}
{'event': 'on_chain_end', 'name': 'reverse_word', 'run_id': 'c4882303-8867-4dff-b031-7d9499b39dda', 'tags': [], 'metadata': {}, 'data': {'input': 'hello', 'output': 'olleh'}}
{'event': 'on_tool_stream', 'run_id': '384f1710-612e-4022-a6d4-8a7bb0cc757e', 'tags': [], 'metadata': {}, 'name': 'correct_tool', 'data': {'chunk': 'olleh'}}
{'event': 'on_tool_end', 'name': 'correct_tool', 'run_id': '384f1710-612e-4022-a6d4-8a7bb0cc757e', 'tags': [], 'metadata': {}, 'data': {'output': 'olleh'}}
    

å¦‚æœä½ ä»Runnable Lambdasæˆ–@chainsä¸­è°ƒç”¨å¯è¿è¡Œå¯¹è±¡ï¼Œé‚£ä¹ˆå›è°ƒå°†è‡ªåŠ¨ä¼ é€’ã€‚


```python
from langchain_core.runnables import RunnableLambda


async def reverse_and_double(word: str):
    return await reverse_word.ainvoke(word) * 2


reverse_and_double = RunnableLambda(reverse_and_double)

await reverse_and_double.ainvoke("1234")

async for event in reverse_and_double.astream_events("1234", version="v1"):
    print(event)
```

{'event': 'on_chain_start', 'name': 'reverse_word', 'run_id': 'c4882303-8867-4dff-b031-7d9499b39dda', 'tags': [], 'metadata': {}, 'data': {'input': '1234'}}
{'event': 'on_chain_end', 'name': 'reverse_word', 'run_id': 'c4882303-8867-4dff-b031-7d9499b39dda', 'tags': [], 'metadata': {}, 'data': {'input': '1234', 'output': '4321'}}
{'event': 'on_chain_start', 'name': 'reverse_word', 'run_id': 'c4882303-8867-4dff-b031-7d9499b39dda', 'tags': [], 'metadata': {}, 'data': {'input': '4321'}}
{'event': 'on_chain_end', 'name': 'reverse_word', 'run_id': 'c4882303-8867-4dff-b031-7d9499b39dda', 'tags': [], 'metadata': {}, 'data': {'input': '4321', 'output': '1234'}}
{'event': 'on_tool_start', 'run_id': '384f1710-612e-4022-a6d4-8a7bb0cc757e', 'name': 'reverse_and_double', 'tags': [], 'metadata': {}, 'data': {'input': '1234'}}
{'event': 'on_tool_stream', 'run_id': '384f1710-612e-4022-a6d4-8a7bb0cc757e', 'tags': [], 'metadata': {}, 'name': 'reverse_and_double', 'data': {'chunk': '43214321'}}
{'event': 'on_tool_end', 'name': 'reverse_and_double', 'run_id': '384f1710-612e-4022-a6d4-8a7bb0cc757e', 'tags': [], 'metadata': {}, 'data': {'output': '43214321'}}

    {'event': 'on_chain_start', 'run_id': '4fe56c7b-6982-4999-a42d-79ba56151176', 'name': 'reverse_and_double', 'tags': [], 'metadata': {}, 'data': {'input': '1234'}}
    {'event': 'on_chain_start', 'name': 'reverse_word', 'run_id': '335fe781-8944-4464-8d2e-81f61d1f85f5', 'tags': [], 'metadata': {}, 'data': {'input': '1234'}}
    {'event': 'on_chain_end', 'name': 'reverse_word', 'run_id': '335fe781-8944-4464-8d2e-81f61d1f85f5', 'tags': [], 'metadata': {}, 'data': {'input': '1234', 'output': '4321'}}
    {'event': 'on_chain_stream', 'run_id': '4fe56c7b-6982-4999-a42d-79ba56151176', 'tags': [], 'metadata': {}, 'name': 'reverse_and_double', 'data': {'chunk': '43214321'}}
    {'event': 'on_chain_end', 'name': 'reverse_and_double', 'run_id': '4fe56c7b-6982-4999-a42d-79ba56151176', 'tags': [], 'metadata': {}, 'data': {'output': '43214321'}}
    

And with the @chain decorator:


```python
from langchain_core.runnables import chain


@chain
async def reverse_and_double(word: str):
    return await reverse_word.ainvoke(word) * 2


await reverse_and_double.ainvoke("1234")

async for event in reverse_and_double.astream_events("1234", version="v1"):
    print(event)
```
```

    {'event': 'on_chain_start', 'run_id': '7485eedb-1854-429c-a2f8-03d01452daef', 'name': 'reverse_and_double', 'tags': [], 'metadata': {}, 'data': {'input': '1234'}}
    {'event': 'on_chain_start', 'name': 'reverse_word', 'run_id': 'e7cddab2-9b95-4e80-abaf-4b2429117835', 'tags': [], 'metadata': {}, 'data': {'input': '1234'}}
    {'event': 'on_chain_end', 'name': 'reverse_word', 'run_id': 'e7cddab2-9b95-4e80-abaf-4b2429117835', 'tags': [], 'metadata': {}, 'data': {'input': '1234', 'output': '4321'}}
    {'event': 'on_chain_stream', 'run_id': '7485eedb-1854-429c-a2f8-03d01452daef', 'tags': [], 'metadata': {}, 'name': 'reverse_and_double', 'data': {'chunk': '43214321'}}
    {'event': 'on_chain_end', 'name': 'reverse_and_double', 'run_id': '7485eedb-1854-429c-a2f8-03d01452daef', 'tags': [], 'metadata': {}, 'data': {'output': '43214321'}}
    
```