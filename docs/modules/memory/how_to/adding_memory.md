# å¦‚ä½•ä¸º LLMChain æ·»åŠ è®°å¿†

æœ¬ç¬”è®°æœ¬æ¼”ç¤ºäº†å¦‚ä½•åœ¨ LLMChain ä¸­ä½¿ç”¨ Memory ç±»ã€‚åœ¨æœ¬æ¼”ç¤ºä¸­ï¼Œæˆ‘ä»¬å°†æ·»åŠ  `ConversationBufferMemory` ç±»ï¼Œä½†å®žé™…ä¸Šå¯ä»¥ä½¿ç”¨ä»»ä½•è®°å¿†ç±»ã€‚

```python
from langchain.memory import ConversationBufferMemory
from langchain import OpenAI, LLMChain, PromptTemplate
```

æœ€é‡è¦çš„ä¸€æ­¥æ˜¯æ­£ç¡®è®¾ç½®æç¤ºã€‚åœ¨ä¸‹é¢çš„æç¤ºä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸¤ä¸ªè¾“å…¥é”®ï¼šä¸€ä¸ªç”¨äºŽå®žé™…è¾“å…¥ï¼Œå¦ä¸€ä¸ªç”¨äºŽæ¥è‡ª Memory ç±»çš„è¾“å…¥ã€‚é‡è¦çš„æ˜¯ï¼Œç¡®ä¿ PromptTemplate å’Œ ConversationBufferMemory ä¸­çš„é”®åŒ¹é…ï¼ˆ`chat_history`ï¼‰ã€‚

```python

template = """You are a chatbot having a conversation with a human.

{chat_history}

Human: {human_input}
Chatbot:"""

prompt = PromptTemplate(
    input_variables=["chat_history", "human_input"], template=template
)

memory = ConversationBufferMemory(memory_key="chat_history")
```

```python
llm_chain = LLMChain(
    llm=OpenAI(),
    prompt=prompt,
    verbose=True,
    memory=memory,
)
```

```python
llm_chain.predict(human_input="Hi there my friend")
```

    
    
    [1m> Entering new LLMChain chain...[0m
    Prompt after formatting:
    [32;1m[1;3mYou are a chatbot having a conversation with a human.


    Human: Hi there my friend
    Chatbot:[0m
    [1m> Finished LLMChain chain.[0m



    ' Hi there, how are you doing today?'


```python
llm_chain.predict(human_input="Not too bad - how are you?")
```

    
    
    [1m> Entering new LLMChain chain...[0m
    Prompt after formatting:
    [32;1m[1;3mYou are a chatbot having a conversation with a human.


    Human: Hi there my friend
    AI:  Hi there, how are you doing today?
    Human: Not too bad - how are you?
    Chatbot:[0m
    [1m> Finished LLMChain chain.[0m



    " I'm doing great, thank you for asking!"


