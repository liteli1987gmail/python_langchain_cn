# Gradioå·¥å…·

Hugging Face Spacesä¸Šæœ‰æˆåƒä¸Šä¸‡ä¸ªGradioåº”ç”¨ã€‚è¯¥åº“å°†å®ƒä»¬ç½®äºæ‚¨çš„LLMæŒ‡å°–ä¹‹é—´ğŸ§¾

å…·ä½“è€Œè¨€ï¼Œgradio-toolsæ˜¯ä¸€ä¸ªPythonåº“ï¼Œç”¨äºå°†Gradioåº”ç”¨è½¬æ¢ä¸ºå¯ä»¥è¢«å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»£ç†åˆ©ç”¨çš„å·¥å…·ï¼Œä»¥å®Œæˆå…¶ä»»åŠ¡ã€‚ä¾‹å¦‚ï¼ŒLLMå¯ä»¥ä½¿ç”¨Gradioå·¥å…·å°†å…¶åœ¨ç½‘ä¸Šæ‰¾åˆ°çš„è¯­éŸ³è®°å½•è½¬å½•ä¸‹æ¥ï¼Œç„¶åä¸ºæ‚¨è¿›è¡Œæ‘˜è¦ã€‚æˆ–è€…ï¼Œå®ƒå¯ä»¥ä½¿ç”¨å¦ä¸€ä¸ªGradioå·¥å…·å¯¹æ‚¨çš„Google Driveä¸Šçš„æ–‡æ¡£åº”ç”¨OCRï¼Œç„¶åå›ç­”ç›¸å…³é—®é¢˜ã€‚

å¦‚æœæ‚¨æƒ³ä½¿ç”¨çš„ç©ºé—´ä¸æ˜¯é¢„æ„å»ºçš„å·¥å…·ä¹‹ä¸€ï¼Œé‚£ä¹ˆåˆ›å»ºè‡ªå·±çš„å·¥å…·éå¸¸å®¹æ˜“ã€‚è¯·å‚é˜…gradio-toolsæ–‡æ¡£ä¸­çš„æ­¤éƒ¨åˆ†ä»¥è·å–æœ‰å…³å¦‚ä½•æ‰§è¡Œæ­¤æ“ä½œçš„ä¿¡æ¯ã€‚æ¬¢è¿æ‰€æœ‰è´¡çŒ®ï¼

```python
# !pip install gradio_tools
```

## ä½¿ç”¨å·¥å…·

```python
from gradio_tools.tools import StableDiffusionTool
```

```python
local_file_path = StableDiffusionTool().langchain.run(
    "è¯·åˆ›å»ºä¸€å¼ ç‹—æ»‘æ¿ç…§ç‰‡"
)
local_file_path
```

    Loaded as API: https://gradio-client-demos-stable-diffusion.hf.space âœ“
    
    Job Status: Status.STARTING eta: None
    



    '/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/b61c1dd9-47e2-46f1-a47c-20d27640993d/tmp4ap48vnm.jpg'




```python
from PIL import Image
```

```python
im = Image.open(local_file_path)
```

```python
display(im)
```

    
<!-- ![png](gradio_tools_files/gradio_tools_7_0.png) -->
    


## åœ¨ä»£ç†ä¸­ä½¿ç”¨

```python
from langchain.agents import initialize_agent
from langchain.llms import OpenAI
from gradio_tools.tools import (
    StableDiffusionTool,
    ImageCaptioningTool,
    StableDiffusionPromptGeneratorTool,
    TextToVideoTool,
)

from langchain.memory import ConversationBufferMemory

llm = OpenAI(temperature=0)
memory = ConversationBufferMemory(memory_key="chat_history")
tools = [
    StableDiffusionTool().langchain,
    ImageCaptioningTool().langchain,
    StableDiffusionPromptGeneratorTool().langchain,
    TextToVideoTool().langchain,
]

agent = initialize_agent(
    tools, llm, memory=memory, agent="conversational-react-description", verbose=True
)
output = agent.run(
    input=(
        "è¯·åˆ›å»ºä¸€å¼ ç‹—æ»‘æ¿ç…§ç‰‡ "
        "ä½†åœ¨ä½¿ç”¨å›¾åƒç”Ÿæˆå™¨ä¹‹å‰æ”¹è¿›æˆ‘çš„æç¤ºã€‚"
        "è¯·ä¸ºç”Ÿæˆçš„å›¾åƒåŠ æ ‡é¢˜å¹¶åˆ›å»ºä¸€ä¸ªè§†é¢‘ã€‚"
    )
)
```

    Loaded as API: https://gradio-client-demos-stable-diffusion.hf.space âœ“
    Loaded as API: https://taesiri-blip-2.hf.space âœ“
    Loaded as API: https://microsoft-promptist.hf.space âœ“
    Loaded as API: https://damo-vilab-modelscope-text-to-video-synthesis.hf.space âœ“
    [1m> è¿›å…¥æ–°çš„AgentExecutoré“¾...[0m
    [32;1m[1;3mThought: æˆ‘éœ€è¦ä½¿ç”¨å·¥å…·å—ï¼Ÿæ˜¯çš„
    Action: StableDiffusionPromptGenerator
    Actionè¾“å…¥: ä¸€åªæ»‘æ¿ä¸Šçš„ç‹—[0m
    Job Status: Status.STARTING eta: None
    
    Observation: [38;5;200m[1;3mä¸€åªæ»‘æ¿ä¸Šçš„ç‹—ï¼Œæ•°å­—ç»˜ç”»ï¼Œartstationï¼Œæ¦‚å¿µè‰ºæœ¯ï¼Œå¹³æ»‘ï¼Œç„¦ç‚¹æ¸…æ™°ï¼Œæ’å›¾ï¼Œè‰ºæœ¯å®¶ä¸ºartgermå’Œgreg rutkowskiå’Œalphonse mucha[0m
    Thought:[32;1m[1;3m æˆ‘éœ€è¦ä½¿ç”¨å·¥å…·å—ï¼Ÿæ˜¯çš„
    Action: StableDiffusion
    Actionè¾“å…¥: ä¸€åªæ»‘æ¿ä¸Šçš„ç‹—ï¼Œæ•°å­—ç»˜ç”»ï¼Œartstationï¼Œæ¦‚å¿µè‰ºæœ¯ï¼Œå¹³æ»‘ï¼Œç„¦ç‚¹æ¸…æ™°ï¼Œæ’å›¾ï¼Œè‰ºæœ¯å®¶ä¸ºartgermå’Œgreg rutkowskiå’Œalphonse mucha[0m
    Job Status: Status.STARTING eta: None
    
    Job Status: Status.PROCESSING eta: None
    
    Observation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m
    Thought:[32;1m[1;3m æˆ‘éœ€è¦ä½¿ç”¨å·¥å…·å—ï¼Ÿæ˜¯çš„
    Action: ImageCaptioner
    Actionè¾“å…¥: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m
    Job Status: Status.STARTING eta: None
    
    Observation: [33;1m[1;3mä¸€åªååœ¨æ»‘æ¿ä¸Šçš„ç‹—çš„ç»˜ç”»[0m
    Thought:[32;1m[1;3m æˆ‘éœ€è¦ä½¿ç”¨å·¥å…·å—ï¼Ÿæ˜¯çš„
    Action: TextToVideo
    Actionè¾“å…¥: ä¸€åªååœ¨æ»‘æ¿ä¸Šçš„ç‹—çš„ç»˜ç”»[0m
    Job Status: Status.STARTING eta: None
    ç”±äºè¯¥åº”ç”¨ç¨‹åºçš„æµé‡è¿‡å¤§ï¼Œé¢„æµ‹å¤§çº¦éœ€è¦73ç§’ã€‚ä¸ºäº†æ›´å¿«åœ°è¿›è¡Œé¢„æµ‹è€Œæ— éœ€ç­‰å¾…é˜Ÿåˆ—ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¤åˆ¶è¯¥ç©ºé—´ï¼šClient.duplicate(damo-vilab/modelscope-text-to-video-synthesis)
    
    Job Status: Status.IN_QUEUE eta: 73.89824726581574
    ç”±äºè¯¥åº”ç”¨ç¨‹åºçš„æµé‡è¿‡å¤§ï¼Œé¢„æµ‹å¤§çº¦éœ€è¦42ç§’ã€‚ä¸ºäº†æ›´å¿«åœ°è¿›è¡Œé¢„æµ‹è€Œæ— éœ€ç­‰å¾…é˜Ÿåˆ—ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¤åˆ¶è¯¥ç©ºé—´ï¼šClient.duplicate(damo-vilab/modelscope-text-to-video-synthesis)
    
    Job Status: Status.IN_QUEUE eta: 42.49370198879602
    
    Job Status: Status.IN_QUEUE eta: 21.314297944849187
    
    Observation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m
    Thought:[32;1m[1;3m æˆ‘éœ€è¦ä½¿ç”¨å·¥å…·å—ï¼Ÿä¸éœ€è¦
    AI: è¿™æ˜¯ä¸€æ®µååœ¨æ»‘æ¿ä¸Šçš„ç‹—çš„ç»˜ç”»çš„è§†é¢‘ã€‚[0m
    [1m> å®Œæˆé“¾ã€‚[0m

```python

```
