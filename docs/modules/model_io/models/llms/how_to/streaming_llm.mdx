# 流式传输（Streaming）

一些LLM提供流式响应。这意味着您可以在整个响应返回之前开始处理它，而不是等待它完全返回。如果您希望在生成响应时向用户显示响应，或者希望在生成响应时处理响应，这将非常有用。

import StreamingLLM from "@snippets/modules/model_io/models/llms/how_to/streaming_llm.mdx"

<StreamingLLM/>
