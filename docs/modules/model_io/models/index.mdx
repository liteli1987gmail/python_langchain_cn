---
sidebar_position: 1
---
# 语言模型 （ Language models ）

![LangChain](https://pica.zhimg.com/50/v2-56e8bbb52aa271012541c1fe1ceb11a2_r.gif 'LangChain中文网')


LangChain 提供了两种类型模型的接口和集成：

- [LLMs](/docs/modules/model_io/models/llms/): 输入为文本字符串，输出为文本字符串的模型
- [Chat models](/docs/modules/model_io/models/chat/): 由语言模型支持，输入为聊天消息列表，输出为聊天消息的模型

## LLMs vs Chat Models

LLMs 和 Chat Models 有微妙但重要的区别。LangChain 中的 LLMs 是指纯文本补全模型。
它们包装的 API 接受字符串提示作为输入，并输出字符串补全。OpenAI 的 GPT-3 就是 LLM 的实现。
Chat models 通常由 LLMs 支持，但专门用于进行对话。
关键是，它们的提供者 API 公开了与纯文本补全模型不同的接口。它们的输入不是单个字符串，而是聊天消息的列表。通常，这些消息带有发言者（通常为 "System"、"AI" 和 "Human" 之一）。
它们返回一个（"AI"）聊天消息作为输出。GPT-4 和 Anthropic 的 Claude 都是作为 Chat Models 实现的。


为了能够交换 LLMs 和 Chat Models，两者都实现了 Base Language Model 接口。这暴露了公共方法 "predict"（输入字符串，返回字符串）和 "predict messages"（输入消息，返回消息）。
如果您使用特定模型，建议使用该模型类别的特定方法（即 LLMs 的 "predict" 和 Chat Models 的 "predict messages"），
但如果您正在创建一个应该适用于不同类型模型的应用程序，共享接口可能会很有帮助。
