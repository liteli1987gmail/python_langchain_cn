---
sidebar_position: 3
sidebar_label: 集成
---

import CodeBlock from "@theme/CodeBlock";


# 集成: 聊天模型

LangChain提供了许多与不同模型提供者集成的聊天模型实现。它们如下所示:

## `ChatOpenAI`（聊天OpenAI)

import OpenAI from "!!raw-loader!@examples/models/chat/integration_openai.ts";


<CodeBlock language="typescript">{OpenAI}</CodeBlock>


## Azure `ChatOpenAI`（Azure的聊天OpenAI)

import AzureOpenAI from "!!raw-loader!@examples/models/chat/integration_azure_openai.ts";


<CodeBlock language="typescript">{AzureOpenAI}</CodeBlock>


## `ChatAnthropic`（聊天Anthropic)

import Anthropic from "!!raw-loader!@examples/models/chat/integration_anthropic.ts";


<CodeBlock language="typescript">{Anthropic}</CodeBlock>


## `PromptLayerChatOpenAI`（Prompt Layer聊天OpenAI)

可以传入可选的 `returnPromptLayerId` 布尔值来获取像下面这样的 `promptLayerRequestId`。下面是一个获取 PromptLayerChatOpenAI 请求ID 的示例:

```typescript
import { PromptLayerChatOpenAI } from "langchain/chat_models/openai";



const chat = new PromptLayerChatOpenAI({

  returnPromptLayerId: true,

});



const respA = await chat.generate([

  [

    new SystemChatMessage(

      "You are a helpful assistant that translates English to French."

    ),

  ],

]);



console.log(JSON.stringify(respA, null, 3));



/*

  {

    "generations": [

      [

        {

          "text": "Bonjour! Je suis un assistant utile qui peut vous aider à traduire de l'anglais vers le français. Que puis-je faire pour vous aujourd'hui?",

          "message": {

            "type": "ai",

            "data": {

              "content": "Bonjour! Je suis un assistant utile qui peut vous aider à traduire de l'anglais vers le français. Que puis-je faire pour vous aujourd'hui?"

            }

          },

          "generationInfo": {

            "promptLayerRequestId": 2300682

          }

        }

      ]

    ],

    "llmOutput": {

      "tokenUsage": {

        "completionTokens": 35,

        "promptTokens": 19,

        "totalTokens": 54

      }

    }

  }

*/

```


## `Google Vertex AI`（Google 顶点AI)

Vertex AI 实现旨在在 Node.js 中使用，而不是直接从浏览器中使用，因为需要使用服务帐户才能使用。

在运行此代码之前，您应该确保已为相关项目启用了 Vertex AI API，并且已经使用以下方法之一进行了 Google Cloud 身份验证:

- 您已登录帐户（使用 `gcloud auth application-default login`）进入 Google Cloud。
- 您正在运行于允许服务账户所在的机器上。
- 您已下载服务账户凭证，可以使用该服务账户访问该项目。
- 您已下载了允许访问该项目的服务账号的凭证，并将 `GOOGLE_APPLICATION_CREDENTIALS` 环境变量设置为该文件的路径。


```bash npm2yarn
npm install google-auth-library

```


ChatGoogleVertexAI 类的工作方式与其他基于聊天的 LLM 相同，具有一些例外情况:

1. 第一个传入的 `SystemChatMessage` 被映射到 PaLM 模型期望的 "context" 参数。
2. 不允许出现其他 `SystemChatMessage`。
3. 在第一个 `SystemChatMessage` 之后，必须是一串奇数条消息，代表人类和模型之间的对话。
4. 发送的信息必须交错出现，先是人类信息，然后是 AI 回复，然后是人类信息，以此类推。


import ChatGoogleVertexAI from "!!raw-loader!@examples/models/chat/integration_googlevertexai.ts";



<CodeBlock language="typescript">{ChatGoogleVertexAI}</CodeBlock>



此外，还有一个可选的“例子”构造参数，可以帮助模型理解什么是适当的响应。
看起来像。


import ChatGoogleVertexAIExamples from "!!raw-loader!@examples/models/chat/integration_googlevertexai-examples.ts";



<CodeBlock language="typescript">{ChatGoogleVertexAIExamples}</CodeBlock>

